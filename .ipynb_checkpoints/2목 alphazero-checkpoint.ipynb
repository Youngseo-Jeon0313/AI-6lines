{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c3eef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def ucb_score(parent, child):\n",
    "    \"\"\"\n",
    "    The score for an action that would transition between the parent and child.\n",
    "    \"\"\"\n",
    "    prior_score = child.prior * math.sqrt(parent.visit_count) / (child.visit_count + 1)\n",
    "    if child.visit_count > 0:\n",
    "        # The value of the child is from the perspective of the opposing player\n",
    "        value_score = -child.value()\n",
    "    else:\n",
    "        value_score = 0\n",
    "\n",
    "    return value_score + prior_score\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, prior, to_play):\n",
    "        self.visit_count = 0\n",
    "        self.to_play = to_play #누가 두는지\n",
    "        self.prior = prior #prior probability\n",
    "        self.value_sum = 0  #sigma V\n",
    "        self.children = {}  #자식 노드\n",
    "        self.state = None\n",
    "\n",
    "    def expanded(self):\n",
    "        return len(self.children) > 0\n",
    "\n",
    "    def value(self):\n",
    "        if self.visit_count == 0:\n",
    "            return 0  #한번도 방문하지 않았다면 고려하지 않는다\n",
    "        return self.value_sum / self.visit_count\n",
    "\n",
    "    def select_action(self, temperature):\n",
    "        \"\"\"\n",
    "        Select action according to the visit count distribution and the temperature.\n",
    "        \"\"\"\n",
    "        visit_counts = np.array([child.visit_count for child in self.children.values()])\n",
    "        actions = [action for action in self.children.keys()]\n",
    "        if temperature == 0:\n",
    "            action = actions[np.argmax(visit_counts)]\n",
    "        elif temperature == float(\"inf\"):\n",
    "            action = np.random.choice(actions)\n",
    "        else:\n",
    "            # See paper appendix Data Generation\n",
    "            visit_count_distribution = visit_counts ** (1 / temperature)\n",
    "            visit_count_distribution = visit_count_distribution / sum(visit_count_distribution)\n",
    "            action = np.random.choice(actions, p=visit_count_distribution)\n",
    "\n",
    "        return action\n",
    "\n",
    "    def select_child(self):\n",
    "        \"\"\"\n",
    "        Select the child with the highest UCB score.\n",
    "        \"\"\"\n",
    "        best_score = -np.inf\n",
    "        best_action = -1\n",
    "        best_child = None\n",
    "\n",
    "        for action, child in self.children.items():\n",
    "            score = ucb_score(self, child)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_action = action\n",
    "                best_child = child\n",
    "\n",
    "        return best_action, best_child\n",
    "\n",
    "    def expand(self, state, to_play, action_probs):\n",
    "        \"\"\"\n",
    "        We expand a node and keep track of the prior policy probability given by neural network\n",
    "        \"\"\"\n",
    "        self.to_play = to_play\n",
    "        self.state = state\n",
    "        for a, prob in enumerate(action_probs):\n",
    "            if prob != 0:\n",
    "                self.children[a] = Node(prior=prob, to_play=self.to_play * -1)\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Debugger pretty print node info\n",
    "        \"\"\"\n",
    "        prior = \"{0:.2f}\".format(self.prior)\n",
    "        return \"{} Prior: {} Count: {} Value: {}\".format(self.state.__str__(), prior, self.visit_count, self.value())\n",
    "\n",
    "\n",
    "class MCTS:\n",
    "\n",
    "    def __init__(self, game, model, args):\n",
    "        self.game = game\n",
    "        self.model = model\n",
    "        self.args = args\n",
    "    \n",
    "    def run(self, model, state, to_play):\n",
    "\n",
    "        root = Node(0, to_play)\n",
    "    \n",
    "        # EXPAND root\n",
    "        action_probs, value = model.predict(state)\n",
    "        valid_moves = self.game.get_valid_moves(state)\n",
    "        action_probs = action_probs * valid_moves  # mask invalid moves\n",
    "        action_probs /= np.sum(action_probs)\n",
    "        root.expand(state, to_play, action_probs)\n",
    "\n",
    "        for _ in range(self.args['num_simulations']):\n",
    "            node = root\n",
    "            search_path = [node]\n",
    "\n",
    "            # SELECT\n",
    "            while node.expanded():\n",
    "                action, node = node.select_child()\n",
    "                search_path.append(node)\n",
    "\n",
    "            parent = search_path[-2]\n",
    "            state = parent.state\n",
    "            # Now we're at a leaf node and we would like to expand\n",
    "            # Players always play from their own perspective\n",
    "            next_state, _ = self.game.get_next_state(state, player=1, action=action)\n",
    "            # Get the board from the perspective of the other player\n",
    "            next_state = self.game.get_canonical_board(next_state, player=-1)\n",
    "\n",
    "            # The value of the new state from the perspective of the other player\n",
    "            value = self.game.get_reward_for_player(next_state, player=1) #leaf노드인지를 파악하는\n",
    "            if value is None: #게임이 끝나지 않았다면\n",
    "                # If the game has not ended:\n",
    "                # EXPAND\n",
    "                action_probs, value = model.predict(next_state)\n",
    "                valid_moves = self.game.get_valid_moves(next_state)\n",
    "                action_probs = action_probs * valid_moves  # mask invalid moves\n",
    "                action_probs /= np.sum(action_probs)\n",
    "                node.expand(next_state, parent.to_play * -1, action_probs)\n",
    "\n",
    "            self.backpropagate(search_path, value, parent.to_play * -1)\n",
    "\n",
    "        return root\n",
    "\n",
    "    def backpropagate(self, search_path, value, to_play):\n",
    "        \"\"\"\n",
    "        At the end of a simulation, we propagate the evaluation all the way up the tree\n",
    "        to the root.\n",
    "        \"\"\"\n",
    "        for node in reversed(search_path):\n",
    "            node.value_sum += value if node.to_play == to_play else -value\n",
    "            node.visit_count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
