# AI-육목

# 구현 계획

2022.01.04
alpha zero 논문 참고. 기계가 선생처럼 자신이 플레이하는 게임의 룰도 따로 학습하고 자신의 policy network도 꾸준히 update해 나가는 기계학습을 시킬 예정이다.
코드를 분류해보자면 일단,

//mcts.py
mcts tree 구조를 만든다.
tree를 방문할 때 expand, select, backpropagation, evaluation을 기준으로 코드를 나누어 작성한다.
너무 어려운 ..코드는 아직 초보단계인 나에게 너무 어려울 듯 하여 가장 이해가 잘되는 
http://joshvarty.github.io/AlphaZero/ 이 2목(??) 코드를 완전히 이해한 후 작성하려 한다.
아무래도 alphazero의 3가지 핵심 부분은
1. value network
2. policy network
3. monte carlo tree search 
이며, 이 때 3에다가 1,2를 어떻게 조화롭게 넣느냐에 초점을 맞추어 코드를 짤 생각이다.

일단 2목, Muzero와 관련한 논문/코드를 읽어보았고 조금 참고해서 코드를 짜볼 생각이다.
GPU에 관련한 내용은 아직 좀 잘 몰라서(이게 컴퓨터 메모리와 관련한건가?? 좀 잘 모르겠다) 공부를 좀 하다가 구현이 GPU와 관련되는 게 너무 힘들 경우 육목판을
조금 줄이든 그런 식으로 진행할 생각이다.

육목판의 경우 참고해서 구현은 해놓았으나 첫 수는 1번 2번째부터는 2번씩 놓을 수 있도록 구현하도록 바꾸어야 하고,
game.py에 환경설정한 {0,0,0,0,}으로의 tuple값이나 또는 numpy 2차원 배열을 이용해서 html 육목판에 구현하는 것도 조금 배워야 한다 일단은 ㅠㅠ

2022.01.04



